{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f617ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Notice there are both Unsupervised+Supervised UMAP\n",
    "### https://umap-learn.readthedocs.io/en/latest/supervised.html\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib as jl\n",
    "import cebra.datasets\n",
    "from cebra import CEBRA\n",
    "import scipy.io as sio\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "\n",
    "def split_data(neural, continuous_index, train_trial):\n",
    "            split_idx = train_trial*dur \n",
    "            neural_train = neural[:split_idx]\n",
    "            neural_test = neural[split_idx:]\n",
    "            continuous_index_train = continuous_index[:split_idx]\n",
    "            continuous_index_test = continuous_index[split_idx:]\n",
    "            return neural_train,neural_test,continuous_index_train,continuous_index_test\n",
    "dur = 40\n",
    "n_conds = 8\n",
    "angle_to_new_value = {-180: 4,-135: 5,-90: 6,-45: 7,0: 0,45: 1,90: 2,135: 3,180: 4}\n",
    "directory = \"./data/SU_16M1/\"\n",
    "files = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "output_dimension = 2\n",
    "for file in files:\n",
    "    if \"Chewie\" in file: ###  or \"Mihili\" in file \n",
    "        mat_contents = sio.loadmat(os.path.join(directory, file))\n",
    "        filename_parts = file.split(\"_neural_con_dis_index\")\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_embed_M1.npz\"\n",
    "        file_save = os.path.join(directory, new_filename)\n",
    "        print(file_save)\n",
    "\n",
    "        neural = mat_contents['neural_M1']\n",
    "        continuous_index_2d = mat_contents['continuous_index']*10\n",
    "        discrete_index = mat_contents['discrete_index']\n",
    "        \n",
    "        vectorized_map = np.vectorize(lambda x: angle_to_new_value[x])\n",
    "        discrete_index = vectorized_map(discrete_index)\n",
    "        continuous_index = np.hstack((continuous_index_2d, discrete_index*45))\n",
    "        total_trial = int(discrete_index.shape[0]/dur)\n",
    "        train_trial = int(total_trial*0.8)\n",
    "        test_trial = total_trial-train_trial\n",
    "        \n",
    "        neural_train, neural_test, continuous_index_train, continuous_index_test = split_data(neural, continuous_index, train_trial)\n",
    "        target_angle_train = continuous_index_train[:, 2].copy()\n",
    "        target_angle_test = continuous_index_test[:, 2].copy()\n",
    "        \n",
    "        cebra_veldir_model = umap.UMAP(n_neighbors=68,min_dist=0.2475,n_components=2,n_jobs=8,\n",
    "                               random_state=None,metric='euclidean')\n",
    "        ######******* Supervised *******######\n",
    "        cebra_veldir_train = cebra_veldir_model.fit_transform(neural_train, y=target_angle_train)\n",
    "        cebra_veldir_test = cebra_veldir_model.fit_transform(neural_test, y=target_angle_test)\n",
    "        ######******* Unsupervised *******######\n",
    "        cebra_veldir_train = cebra_veldir_model.fit_transform(neural_train)\n",
    "        cebra_veldir_test = cebra_veldir_model.fit_transform(neural_test)\n",
    "        \n",
    "        velocity_reshaped = continuous_index_train[:, 0:2].reshape(train_trial, dur, 2)\n",
    "        locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "        truth_XY = locations.reshape(train_trial*dur, 2)\n",
    "        \n",
    "        X = cebra_veldir_train\n",
    "        y = continuous_index_train[:, 0:2]\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        pred_vel = reg.predict(X) \n",
    "        y_C = continuous_index_train[:, 2]\n",
    "        LogisticReg = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "        LogisticReg.fit(X, y_C)\n",
    "        pred_dir = LogisticReg.predict(X)\n",
    "\n",
    "        velocity_reshaped = pred_vel.reshape(train_trial, dur, 2)\n",
    "        locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "        pred_XY = locations.reshape(train_trial*dur, 2)\n",
    "        \n",
    "        posi_r2 = sklearn.metrics.r2_score(truth_XY, pred_XY) ### proportion of total variation explained by model\n",
    "        vel_r2 = sklearn.metrics.r2_score(continuous_index_train[:, 0:2], pred_vel)\n",
    "        \n",
    "        differences = abs(pred_dir - target_angle_train)\n",
    "        angle_diffs = np.where(differences > 180, 360 - differences, differences)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = plt.subplot(121)\n",
    "        ax1.scatter(truth_XY[:, 0], truth_XY[:, 1], alpha=1, color=plt.cm.hsv(1/360*target_angle_train), s=0.3)\n",
    "        ax1.spines[\"right\"].set_visible(False)\n",
    "        ax1.spines[\"top\"].set_visible(False)\n",
    "        plt.title('Var-R2 vel='+str(round(reg.score(X, y), 3))+' dir='+str(round(LogisticReg.score(X, y_C), 3))\\\n",
    "                 +' MAE='+str(round(np.mean(angle_diffs),1)))\n",
    "        \n",
    "        ax2 = plt.subplot(122)\n",
    "        ax2.scatter(pred_XY[:, 0], pred_XY[:, 1], alpha=1, color=plt.cm.hsv(1/360*pred_dir), s=0.3)\n",
    "        ax2.spines[\"right\"].set_visible(False)\n",
    "        ax2.spines[\"top\"].set_visible(False)\n",
    "        plt.title('True vs Pred-R2 vel='+str(round(vel_r2, 3))+' pos='+str(round(posi_r2, 3)))\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_Decoding.pdf\"\n",
    "        output_path = os.path.join(directory, new_filename)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        idx1, idx2= 0, 1\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=250)\n",
    "        ax = plt.subplot(121)\n",
    "        norm = plt.Normalize(vmin=0, vmax=1) ### Ensures full range from 0 to 1 is used ****NECESSARY\n",
    "        x = ax.scatter(cebra_veldir_train[:, idx1],cebra_veldir_train[:, idx2],c=target_angle_train/360,\n",
    "                       cmap=plt.cm.hsv, edgecolors='none', norm=norm, alpha=0.75,s=5)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        xlims = ax.get_xlim()\n",
    "        ylims = ax.get_ylim()\n",
    "        ax = plt.subplot(122)\n",
    "        for i in range(8):\n",
    "            direction_trial = (target_angle_train//45 == i)\n",
    "            trial_avg = cebra_veldir_train[direction_trial, :].reshape(-1,dur,output_dimension).mean(axis=0)\n",
    "            ax.scatter(trial_avg[:, idx1],trial_avg[:, idx2],\n",
    "                       color=plt.cm.hsv(1 / 8 * i), edgecolors='none', alpha=0.75, s=10)\n",
    "            ax.plot(trial_avg[:, idx1],trial_avg[:, idx2],\n",
    "                color=plt.cm.hsv(1 / 8 * i),linewidth=0.5, alpha=0.75)  \n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(xlims)\n",
    "        ax.set_ylim(ylims)\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_Embedding.pdf\"\n",
    "        output_path = os.path.join(directory, new_filename)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "        np.savez(file_save,\n",
    "                cebra_veldir_train=cebra_veldir_train,\n",
    "                 cebra_veldir_test=cebra_veldir_test,\n",
    "                 continuous_index_train=continuous_index_train,\n",
    "                 continuous_index_test=continuous_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a82faa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Chewie_150319_embed_M1.npz\n",
      "./data/Chewie_150629_embed_M1.npz\n",
      "./data/Chewie_150313_embed_M1.npz\n",
      "./data/Chewie_150630_embed_M1.npz\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "### it requires 8 different target angles for alignment(averaging over trials)\n",
    "### from sklearn.preprocessing import StandardScaler >>> unnecessary\n",
    "output_dimension = 3\n",
    "for file in files:\n",
    "    if \"Chewie\" in file: ###  or \"Mihili\" in file \n",
    "        mat_contents = sio.loadmat(os.path.join(directory, file))\n",
    "        filename_parts = file.split(\"_neural_con_dis_index\")\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_embed_M1.npz\"\n",
    "        file_save = os.path.join(directory, new_filename)\n",
    "        print(file_save)\n",
    "\n",
    "        neural = mat_contents['neural_M1']\n",
    "        continuous_index_2d = mat_contents['continuous_index']*10\n",
    "        discrete_index = mat_contents['discrete_index']\n",
    "        \n",
    "        vectorized_map = np.vectorize(lambda x: angle_to_new_value[x])\n",
    "        discrete_index = vectorized_map(discrete_index)\n",
    "        continuous_index = np.hstack((continuous_index_2d, discrete_index*45))\n",
    "        total_trial = int(discrete_index.shape[0]/dur)\n",
    "        train_trial = int(total_trial*0.8)\n",
    "        test_trial = total_trial-train_trial\n",
    "        \n",
    "        neural_train, neural_test, continuous_index_train, continuous_index_test = split_data(neural, continuous_index, train_trial)\n",
    "        target_angle_train = continuous_index_train[:, 2].copy()\n",
    "        target_angle_test = continuous_index_test[:, 2].copy()\n",
    "\n",
    "        n_neurons = neural_train.shape[1]\n",
    "        rates = [] \n",
    "        for i in range(n_conds):\n",
    "            direction_trial = (target_angle_train//45 == i)\n",
    "            trial_no_avg = neural_train[direction_trial, :].reshape(-1,n_neurons) ### 3D(Xtrials*40bin, 86neurons)\n",
    "            rates.append(trial_no_avg)\n",
    "        rate_stack = np.vstack(rates) ## (33200, 86)  \n",
    "        pca = PCA(n_components=3)\n",
    "#         rate_scaled = StandardScaler().fit_transform(rate_stack)\n",
    "        pca_emb_train = pca.fit_transform(rate_stack) ### output==2D(33200, 3dims)\n",
    "\n",
    "        rates = [] \n",
    "        for i in range(n_conds):\n",
    "            direction_trial = (target_angle_test//45 == i)\n",
    "            trial_no_avg = neural_test[direction_trial, :].reshape(-1,n_neurons) ### 3D(Xtrials*40bin, 86neurons)\n",
    "            rates.append(trial_no_avg)\n",
    "        rate_stack = np.vstack(rates) ## (33200, 86)  \n",
    "        pca = PCA(n_components=3)\n",
    "        pca_emb_test = pca.fit_transform(rate_stack) ### output==2D(33200, 3dims)\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 5), dpi=250)\n",
    "        ax = fig.add_subplot(121, projection='3d')\n",
    "        ax.scatter(pca_emb_train[:, 0],pca_emb_train[:, 1],pca_emb_train[:, 2],\n",
    "                       c=target_angle_train/360, cmap=plt.cm.hsv,edgecolors='none',alpha=0.75,s=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        xlims = ax.get_xlim()\n",
    "        ylims = ax.get_ylim()\n",
    "        zlims = ax.get_zlim()\n",
    "        ax.grid(False)\n",
    "\n",
    "        \n",
    "        ax = fig.add_subplot(122, projection='3d')\n",
    "        rates = [] \n",
    "        for i in range(n_conds):\n",
    "            direction_trial = (target_angle_train//45 == i)\n",
    "            trial_avg = neural_train[direction_trial, :].reshape(-1,dur,n_neurons).mean(axis=0) ### (40bin, 86neurons)\n",
    "            rates.append(trial_avg)\n",
    "        ### rates = StandardScaler().fit_transform(rates) >>>Fail, only for 1 or 2 dimensions\n",
    "        rate_stack_avg = np.vstack(rates) ## 2D(8conds*40bin, 86neurons)\n",
    "        pca = PCA(n_components=3)\n",
    "#         rate_scaled = StandardScaler().fit_transform(rate_stack_avg)\n",
    "        pca_emb_avg = pca.fit_transform(rate_stack_avg) ### output==2D(8conds*40bin, 3dims)\n",
    "        pca_emb_avg = pca_emb_avg.reshape((n_conds, len(rates[0]), -1)) ### 3D(8conds, 40bin, 3dim)\n",
    "\n",
    "        i = 0\n",
    "        for traj in pca_emb_avg: ### traj==(40, 3)\n",
    "            ax.plot(traj[:, 0],traj[:, 1],traj[:, 2],color=plt.cm.hsv(1/n_conds*i),linewidth=0.25)\n",
    "            ax.scatter(traj[:, 0], traj[:, 1], traj[:, 2], color=plt.cm.hsv(1 / n_conds * i), s=3)\n",
    "            ## ax.scatter(traj[0, 0], traj[0, 1], traj[0, 2],s=3) ### starting point\n",
    "            i = i +1\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        ax.grid(False)\n",
    "\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_Embedding_PCA.pdf\"\n",
    "        output_path = os.path.join(directory, new_filename)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        np.savez(file_save,\n",
    "                 cebra_veldir_train=pca_emb_avg,\n",
    "                 continuous_index_train=continuous_index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce69a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Chewie_150319_embed_M1.npz\n",
      "You chose to determine the regularization parameter automatically. This can\n",
      "                    take substantial time and grows linearly with the number of crossvalidation\n",
      "                    folds. The latter can be set by changing self.n_trials (default = 3). Similarly,\n",
      "                    use self.protect to set the list of axes that are not supposed to get to get shuffled\n",
      "                    (e.g. upon splitting the data into test- and training, time-points should always\n",
      "                    be drawn from the same trial, i.e. self.protect = ['t']). This can significantly\n",
      "                    speed up the code.\n",
      "Start optimizing regularization.\n",
      "Starting trial  1 / 3\n",
      "Starting trial  2 / 3\n",
      "Starting trial  3 / 3\n",
      "Optimized regularization, optimal lambda =  0.006640873038344959\n",
      "Regularization will be fixed; to compute the optimal                    parameter again on the next fit, please                    set opt_regularizer_flag to True.\n",
      "./data/Chewie_150629_embed_M1.npz\n",
      "You chose to determine the regularization parameter automatically. This can\n",
      "                    take substantial time and grows linearly with the number of crossvalidation\n",
      "                    folds. The latter can be set by changing self.n_trials (default = 3). Similarly,\n",
      "                    use self.protect to set the list of axes that are not supposed to get to get shuffled\n",
      "                    (e.g. upon splitting the data into test- and training, time-points should always\n",
      "                    be drawn from the same trial, i.e. self.protect = ['t']). This can significantly\n",
      "                    speed up the code.\n",
      "Start optimizing regularization.\n",
      "Starting trial  1 / 3\n",
      "Starting trial  2 / 3\n",
      "Starting trial  3 / 3\n",
      "Optimized regularization, optimal lambda =  0.009297222253682942\n",
      "Regularization will be fixed; to compute the optimal                    parameter again on the next fit, please                    set opt_regularizer_flag to True.\n",
      "./data/Chewie_150313_embed_M1.npz\n",
      "You chose to determine the regularization parameter automatically. This can\n",
      "                    take substantial time and grows linearly with the number of crossvalidation\n",
      "                    folds. The latter can be set by changing self.n_trials (default = 3). Similarly,\n",
      "                    use self.protect to set the list of axes that are not supposed to get to get shuffled\n",
      "                    (e.g. upon splitting the data into test- and training, time-points should always\n",
      "                    be drawn from the same trial, i.e. self.protect = ['t']). This can significantly\n",
      "                    speed up the code.\n",
      "Start optimizing regularization.\n",
      "Starting trial  1 / 3\n",
      "Starting trial  2 / 3\n",
      "Starting trial  3 / 3\n",
      "Optimized regularization, optimal lambda =  0.004743480741674971\n",
      "Regularization will be fixed; to compute the optimal                    parameter again on the next fit, please                    set opt_regularizer_flag to True.\n",
      "./data/Chewie_150630_embed_M1.npz\n",
      "You chose to determine the regularization parameter automatically. This can\n",
      "                    take substantial time and grows linearly with the number of crossvalidation\n",
      "                    folds. The latter can be set by changing self.n_trials (default = 3). Similarly,\n",
      "                    use self.protect to set the list of axes that are not supposed to get to get shuffled\n",
      "                    (e.g. upon splitting the data into test- and training, time-points should always\n",
      "                    be drawn from the same trial, i.e. self.protect = ['t']). This can significantly\n",
      "                    speed up the code.\n",
      "Start optimizing regularization.\n",
      "Starting trial  1 / 3\n",
      "Starting trial  2 / 3\n",
      "Starting trial  3 / 3\n",
      "Optimized regularization, optimal lambda =  0.009297222253682942\n",
      "Regularization will be fixed; to compute the optimal                    parameter again on the next fit, please                    set opt_regularizer_flag to True.\n"
     ]
    }
   ],
   "source": [
    "from dPCA import dPCA\n",
    "### it requires 8 different target angles for alignment\n",
    "output_dimension = 3\n",
    "for file in files:\n",
    "    if \"Chewie\" in file: ###  or \"Mihili\" in file \n",
    "        mat_contents = sio.loadmat(os.path.join(directory, file))\n",
    "        filename_parts = file.split(\"_neural_con_dis_index\")\n",
    "        ### new_filename = filename_parts[0] + \"_embed_M1.npz\"\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_embed_M1.npz\"\n",
    "        file_save = os.path.join(directory, new_filename)\n",
    "        print(file_save)\n",
    "\n",
    "        neural = mat_contents['neural_M1']\n",
    "        continuous_index_2d = mat_contents['continuous_index']*10\n",
    "        discrete_index = mat_contents['discrete_index']\n",
    "        \n",
    "        vectorized_map = np.vectorize(lambda x: angle_to_new_value[x])\n",
    "        discrete_index = vectorized_map(discrete_index)\n",
    "        continuous_index = np.hstack((continuous_index_2d, discrete_index*45))\n",
    "        total_trial = int(discrete_index.shape[0]/dur)\n",
    "        train_trial = int(total_trial*0.8)\n",
    "        test_trial = total_trial-train_trial\n",
    "        \n",
    "        neural_train, neural_test, continuous_index_train, continuous_index_test = split_data(neural, continuous_index, train_trial)\n",
    "        target_angle_train = continuous_index_train[:, 2].copy()\n",
    "        target_angle_test = continuous_index_test[:, 2].copy()\n",
    "\n",
    "        n_neurons = neural_train.shape[1]\n",
    "        stimuli_trials = np.zeros(n_conds)\n",
    "        for i in range(n_conds):\n",
    "            direction_trial = (target_angle_train//45 == i)\n",
    "            trial_dur_neuron = neural_train[direction_trial, :].reshape(-1,dur,n_neurons) ### (Xtrials, 40bin, 86neurons)\n",
    "            stimuli_trials[i] = trial_dur_neuron.shape[0]\n",
    "        min_trials = min(stimuli_trials).astype(int)\n",
    "        rates_trial = []\n",
    "        for i in range(n_conds):\n",
    "            direction_trial = (target_angle_train//45 == i)\n",
    "            trial_dur_neuron = neural_train[direction_trial, :].reshape(-1,dur,n_neurons) ### (Xtrials, 40bin, 86neurons)\n",
    "            trial_single = trial_dur_neuron[:min_trials, :, :] ##(min-trials, 40, 86)\n",
    "            rates_trial.append(trial_single)\n",
    "        rate_stack_avg = np.stack(rates_trial, axis=-1)   ## (97, 40, 86, 8)\n",
    "        trialR = np.transpose(rate_stack_avg, (0, 2, 3, 1)) ## (97trials, 86neurons, 8stimuli, 40bin)\n",
    "\n",
    "        ### trial-average data over axis 0\n",
    "        R = np.mean(trialR,0)\n",
    "        # ### example code: center data\n",
    "        R_temp = R.reshape((n_neurons,-1)) ### (Xneurons, 40bin*8stimuli)\n",
    "        R -= np.mean(R_temp,1)[:,None,None] ### minus averaged response from all bin's for each neuron\n",
    "        dpca = dPCA.dPCA(labels='st',regularizer='auto', n_components=3) ###default component is 10\n",
    "        dpca.protect = ['t']\n",
    "        # ### R =      3D(            100neurons, 6stimuli, 250time-points)\n",
    "        # ### trialR = 4D(10trials,   100neurons, 6stimuli, 250time-points)\n",
    "        # ### Z['s']=Z['t']=Z['st'] (Xcomponents, 6stimuli, 250time-points)\n",
    "        Z = dpca.fit_transform(R,trialR)\n",
    "        \n",
    "        time = range(dur)\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(131)\n",
    "        for s in range(n_conds):\n",
    "            plt.plot(time,Z['t'][0,s])\n",
    "        plt.title('1st time component') \n",
    "        plt.subplot(132)\n",
    "        for s in range(n_conds):\n",
    "            plt.plot(time,Z['s'][0,s])   \n",
    "        plt.title('1st stimulus component')   \n",
    "        plt.subplot(133)\n",
    "        for s in range(n_conds):\n",
    "            plt.plot(time,Z['st'][0,s])   \n",
    "        plt.title('1st mixing component')\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_time_stimuli_mix_component.pdf\"\n",
    "        output_path = os.path.join(directory, new_filename)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        dPCA_embed = Z['s'] ### (3emb-dim, 8stimuli, 40bin)\n",
    "        fig = plt.figure(figsize=(9, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in range(n_conds):\n",
    "            ax.scatter(dPCA_embed[0, i, :],dPCA_embed[1, i, :],dPCA_embed[2, i, :],\n",
    "                       color=plt.cm.hsv(1 / 8 * i),edgecolors='none',alpha=1,s=10)\n",
    "            ax.plot(dPCA_embed[0, i, :], dPCA_embed[1, i, :], dPCA_embed[2, i, :],\n",
    "                    color=plt.cm.hsv(1 / 8 * i),linewidth=0.25,alpha=1) \n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        ax.set_xlabel('PC1')\n",
    "        ax.set_ylabel('PC2')\n",
    "        ax.set_zlabel('PC3')\n",
    "        new_filename = filename_parts[0][:7]+filename_parts[0][-6:] + \"_Embedding_dPCA.pdf\"\n",
    "        output_path = os.path.join(directory, new_filename)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        np.savez(file_save,\n",
    "                 cebra_veldir_train=dPCA_embed,\n",
    "                 continuous_index_train=continuous_index_train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28a56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc327929684d2c13e929b2699e1b37518dbb61b921da51c352c926069002ee0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
