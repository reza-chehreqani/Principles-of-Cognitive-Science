{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebd2668",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vel_test_r2= 0.702426333732958\n",
      "#1 self compare\n",
      "vel_test_r2= 0.6414935940186965\n",
      "#5 self compare\n",
      "vel_test_r2= 0.6705147422030597\n",
      "#9 self compare\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "import sklearn.metrics\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from itertools import permutations, combinations\n",
    "dur = 35\n",
    "emb_dim = 3\n",
    "N_angles = 8\n",
    "\n",
    "directory = './data_NER/S1 3/NER_Han2017/NPZ/'\n",
    "name_range = slice(-28, -22)\n",
    "file_save = \"./data_NER/Fig7/NER_Han2017.npz\"\n",
    "\n",
    "# directory = './data_NER/S1 3/Cebra_Han2017/NPZ/'\n",
    "# name_range = slice(-28, -22)\n",
    "# file_save = \"./data_NER/Fig7/Cebra_Han2017.npz\"\n",
    "\n",
    "# directory = './data_NER/S1 3/piVAE_Han2017/NPZ/'\n",
    "# name_range = slice(-19, -13)\n",
    "# file_save = \"./data_NER/Fig7/piVAE_Han2017.npz\"\n",
    "\n",
    "def get_best_R(R_all, emb_A, emb_A_8angle_align):\n",
    "    determinants = [np.linalg.det(R_all[:, :, i]) for i in range(R_all.shape[2])]\n",
    "    positive_dets = [det for det in determinants if det >= 0]\n",
    "    negative_dets = [det for det in determinants if det < 0]\n",
    "\n",
    "    if len(positive_dets)>0:\n",
    "        target_dets = positive_dets\n",
    "        differences = [abs(abs(det) - 1) for det in target_dets]\n",
    "        min_index = np.argmin(differences)\n",
    "        best_R_index_p = determinants.index(positive_dets[min_index])\n",
    "        best_R_p = R_all[:, :, best_R_index_p]\n",
    "        emb_A_whole_align_p = np.matmul(emb_A, best_R_p)\n",
    "        align_diff_p = np.sum(abs(emb_A_whole_align_p-emb_A_8angle_align))\n",
    "        ## print('diff positive detR=', align_diff_p)\n",
    "    elif len(positive_dets) == 0:\n",
    "        align_diff_p = 5000000 ### arbitory value\n",
    "        \n",
    "    if len(negative_dets)>0:\n",
    "        target_dets = negative_dets\n",
    "        differences = [abs(abs(det) - 1) for det in target_dets]\n",
    "        min_index = np.argmin(differences)\n",
    "        best_R_index_n = determinants.index(negative_dets[min_index])\n",
    "        best_R_n = R_all[:, :, best_R_index_n]\n",
    "        emb_A_whole_align_n = np.matmul(emb_A, best_R_n)\n",
    "        align_diff_n = np.sum(abs(emb_A_whole_align_n-emb_A_8angle_align))\n",
    "        ## print('diff negative detR=', align_diff_n)\n",
    "    elif len(negative_dets) == 0:\n",
    "        align_diff_n = 5000000\n",
    "        \n",
    "    if align_diff_p<align_diff_n:\n",
    "        best_R = best_R_p\n",
    "        ## print('Using positive R')\n",
    "    elif align_diff_p>align_diff_n:\n",
    "        best_R = best_R_n\n",
    "        ## print('Using negative R')\n",
    "    return best_R\n",
    "\n",
    "\n",
    "def cross_decode(file_path1, file_path2):\n",
    "    Monkey_A = np.load(file_path1)\n",
    "    XYTarget_A = np.concatenate((Monkey_A['continuous_index_train'], Monkey_A['continuous_index_test']), axis=0)\n",
    "    emb_A = np.concatenate((Monkey_A['cebra_veldir_train'], Monkey_A['cebra_veldir_test']), axis=0)\n",
    "    if np.max(XYTarget_A[:, 2])>10: ### angles in 0-45-90-...315degrees\n",
    "        XYTarget_A[:, 2] = XYTarget_A[:, 2]/45\n",
    "        \n",
    "    Monkey_B = np.load(file_path2)\n",
    "    XYTarget_B = np.concatenate((Monkey_B['continuous_index_train'], Monkey_B['continuous_index_test']), axis=0)\n",
    "    emb_B = np.concatenate((Monkey_B['cebra_veldir_train'], Monkey_B['cebra_veldir_test']), axis=0)\n",
    "    if np.max(XYTarget_B[:, 2])>10:\n",
    "        XYTarget_B[:, 2] = XYTarget_B[:, 2]/45\n",
    "    \n",
    "    train_trial_A = int(Monkey_A['continuous_index_train'].shape[0]/dur)\n",
    "    test_trial_A = int(Monkey_A['continuous_index_test'].shape[0]/dur)\n",
    "    train_trial_B = int(Monkey_B['continuous_index_train'].shape[0]/dur)\n",
    "    test_trial_B = int(Monkey_B['continuous_index_test'].shape[0]/dur)\n",
    "    \n",
    "    R_all = np.zeros((emb_dim, emb_dim, N_angles))\n",
    "    for a in range(N_angles):\n",
    "        direction_trial = (XYTarget_A[:, 2] == a)\n",
    "        trial_avg_A = emb_A[direction_trial, :].reshape(-1,dur,emb_dim).mean(axis=0)\n",
    "        direction_trial = (XYTarget_B[:, 2] == a)\n",
    "        trial_avg_B = emb_B[direction_trial, :].reshape(-1,dur,emb_dim).mean(axis=0)\n",
    "        R, sca = orthogonal_procrustes(trial_avg_A, trial_avg_B) ### both are (dur, 3emb-dim)\n",
    "        R_all[:,:, a] = R\n",
    "        det_R = np.linalg.det(R)\n",
    "    trial_arrays = []\n",
    "    for i in range(N_angles):\n",
    "        direction_trial = (XYTarget_A[:, 2] == i)\n",
    "        trial_A = emb_A[direction_trial, :].reshape(-1,dur,emb_dim)\n",
    "        trial_A = np.matmul(trial_A, R_all[:,:,i])\n",
    "        trial_arrays.append((direction_trial, trial_A))\n",
    "    emb_A_8angle_align = np.empty_like(emb_A)\n",
    "    for mask, trial_data in trial_arrays: ### loop-through 8 times=angles\n",
    "        flat_data = trial_data.reshape(-1, emb_dim) ### (n-trials*dur, 3emb-dim)\n",
    "        emb_A_8angle_align[mask, :] = flat_data \n",
    "     \n",
    "    emb_A_whole_align = np.matmul(emb_A, get_best_R(R_all, emb_A, emb_A_8angle_align))\n",
    "    \n",
    "    continuous_index_train = XYTarget_A[:train_trial_A*dur, :]\n",
    "    cebra_veldir_train = emb_A_whole_align[:train_trial_A*dur, :] ####***** three choices here *****####\n",
    "    continuous_index_test_B = XYTarget_B[-test_trial_B*dur:, :]\n",
    "    cebra_veldir_test_B = emb_B[-test_trial_B*dur:, :]\n",
    "    \n",
    "    X = cebra_veldir_train\n",
    "    y = continuous_index_train[:, 0:2]\n",
    "    y_C = continuous_index_train[:, 2]\n",
    "    reg = LinearRegression().fit(X, y) ### n_jobs = 8 >>> unnecessary\n",
    "    pred_vel = reg.predict(X) \n",
    "    LogisticReg = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "    LogisticReg.fit(X, y_C)\n",
    "    ###******** this part will use previous trained \"reg & LogisticReg\" ###********\n",
    "    ###******** this part will use previous trained \"reg & LogisticReg\" ###********\n",
    "    X = cebra_veldir_test_B\n",
    "    y = continuous_index_test_B[:, 0:2]\n",
    "    y_C = continuous_index_test_B[:, 2]\n",
    "    pred_vel_test = reg.predict(X) \n",
    "    velocity_reshaped = y.reshape(test_trial_B, dur, 2)\n",
    "    locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "    truth_XY = locations.reshape(test_trial_B*dur, 2)\n",
    "    velocity_reshaped = pred_vel_test.reshape(test_trial_B, dur, 2)\n",
    "    locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "    pred_XY = locations.reshape(test_trial_B*dur, 2)\n",
    "\n",
    "    posi_test_r2 = sklearn.metrics.r2_score(truth_XY, pred_XY)\n",
    "    vel_test_r2 = sklearn.metrics.r2_score(pred_vel_test, y)\n",
    "\n",
    "    pred_dir_test = LogisticReg.predict(X)\n",
    "    pred_dir_acc = np.zeros((dur, test_trial_B))\n",
    "    for i in range(test_trial_B): ## test_trial\n",
    "        t_pred = pred_dir_test[dur*(i):dur*(i+1)]\n",
    "        t_truth = y_C[dur*(i):dur*(i+1)]\n",
    "        pred_dir_acc[np.where(t_pred == t_truth), i] = 1\n",
    "    acc_time = 100*np.sum(pred_dir_acc, axis=1)/test_trial_B\n",
    "    pred_max_acc = np.max(acc_time)\n",
    "    return posi_test_r2,vel_test_r2,pred_max_acc,acc_time\n",
    "\n",
    "def self_decode(file_path1):\n",
    "    Monkey_A = np.load(file_path1)\n",
    "    X = Monkey_A['cebra_veldir_train']\n",
    "    y = Monkey_A['continuous_index_train'][:, 0:2]\n",
    "    y_C = Monkey_A['continuous_index_train'][:, 2]\n",
    "\n",
    "    train_trial_A = int(y.shape[0]/dur)\n",
    "    velocity_reshaped = y.reshape(train_trial_A, dur, 2)\n",
    "    locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "    truth_XY = locations.reshape(train_trial_A*dur, 2)\n",
    "    \n",
    "    reg = LinearRegression().fit(X, y) ### n_jobs = 8 >>> unnecessary\n",
    "    pred_vel = reg.predict(X) \n",
    "    LogisticReg = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "    LogisticReg.fit(X, y_C)\n",
    "    ###******** this part will use previous trained \"reg & LogisticReg\" ###********\n",
    "    ###******** this part will use previous trained \"reg & LogisticReg\" ###********\n",
    "    X = Monkey_A['cebra_veldir_test']\n",
    "    y = Monkey_A['continuous_index_test'][:,0:2]\n",
    "    y_C = Monkey_A['continuous_index_test'][:, 2]\n",
    "    \n",
    "    pred_vel_test = reg.predict(X)\n",
    "    test_trial_A = int(y.shape[0]/dur)\n",
    "    velocity_reshaped = y.reshape(test_trial_A, dur, 2)\n",
    "    locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "    truth_XY = locations.reshape(test_trial_A*dur, 2)\n",
    "    velocity_reshaped = pred_vel_test.reshape(test_trial_A, dur, 2)\n",
    "    locations = np.cumsum(velocity_reshaped, axis=1)\n",
    "    pred_XY = locations.reshape(test_trial_A*dur, 2)\n",
    "\n",
    "    posi_test_r2 = sklearn.metrics.r2_score(truth_XY, pred_XY)\n",
    "    vel_test_r2 = sklearn.metrics.r2_score(pred_vel_test, y) ## default is \"uniform_average\"\n",
    "    print('vel_test_r2=', vel_test_r2) ## two values for XY if using 'raw_values';otherwise, average X&Y\n",
    "\n",
    "    pred_dir_test = LogisticReg.predict(X)     \n",
    "    pred_dir_matches = pred_dir_test == y_C\n",
    "    pred_dir_test_acc = 100*np.sum(pred_dir_matches)/test_trial_A/dur\n",
    "    differences = 45*abs(pred_dir_test - y_C)\n",
    "    angle_diffs = np.where(differences > 180, 360 - differences, differences)\n",
    "    dir_test_r2 = sklearn.metrics.r2_score(pred_dir_test, y_C)\n",
    "    \n",
    "    pred_dir_acc = np.zeros((dur, test_trial_A))\n",
    "    for i in range(test_trial_A):\n",
    "        t_pred = pred_dir_test[dur*(i):dur*(i+1)]\n",
    "        t_truth = y_C[dur*(i):dur*(i+1)]\n",
    "        pred_dir_acc[np.where(t_pred == t_truth), i] = 1\n",
    "    acc_time = 100*np.sum(pred_dir_acc, axis=1)/test_trial_A\n",
    "    pred_max_acc = np.max(acc_time)\n",
    "\n",
    "    return posi_test_r2, vel_test_r2, pred_max_acc, acc_time, pred_vel_test, y_C\n",
    "            \n",
    "### List all files in the directory\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "n = len(files)\n",
    "pos_R_2D = np.zeros((n, n))\n",
    "vel_R_2D = np.zeros((n, n))\n",
    "peak_acc_2D = np.zeros((n, n))\n",
    "acc_time_2D = np.zeros((dur, n*n))\n",
    "date_subjects = []\n",
    "n_compare = 0\n",
    "\n",
    "def list_and_sort_files(directory):\n",
    "    # List all files\n",
    "    files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    def extract_date(filename):\n",
    "        # This regex matches 6 consecutive digits that likely represent a date in YYMMDD format\n",
    "        match = re.search(r'(\\d{6})', os.path.basename(filename))\n",
    "        date = match.group(0) if match else '000000'  # Default to '000000' if no date is found\n",
    "        # Standardize to YYMMDD if necessary\n",
    "        year_prefix = '20'  # assuming all dates are after the year 2000\n",
    "        return int(year_prefix + date) if len(date) == 6 else int(date)\n",
    "    sorted_files = sorted(files, key=extract_date)\n",
    "    return sorted_files\n",
    "sorted_files=list_and_sort_files(directory)\n",
    "\n",
    "for i, file1 in enumerate(sorted_files):\n",
    "    # print(\"Reading file:\", file1)\n",
    "    for j, file2 in enumerate(sorted_files):\n",
    "        if i != j:    ### with-others\n",
    "            posi_test_r2,vel_test_r2,pred_max_acc,acc_time = cross_decode(file1, file2)\n",
    "            # print('#'+str(n_compare+1)+' cross compare')\n",
    "        elif i == j:  ### with-itself\n",
    "            posi_test_r2,vel_test_r2,pred_max_acc,acc_time, vel_pred, vel_real = self_decode(file1)\n",
    "            print('#'+str(n_compare+1)+' self compare')\n",
    "        pos_R_2D[i, j] = posi_test_r2\n",
    "        vel_R_2D[i, j] = vel_test_r2\n",
    "        peak_acc_2D[i, j] = pred_max_acc\n",
    "        acc_time_2D[:, n_compare] = acc_time\n",
    "        if \"M1PMd\" in directory:\n",
    "            date = file1[-29:-23]\n",
    "            suffix = file1[-7:-5]\n",
    "            date_subjects.append(f\"{date}{suffix}\")  \n",
    "        elif \"M1PMd\" not in directory:\n",
    "            # print(file1[name_range])\n",
    "            date_subjects.append(file1[name_range])\n",
    "        n_compare = n_compare+1\n",
    "# print('label of date:', np.unique(date_subjects))\n",
    "\n",
    "np.savez(file_save, date_subjects = date_subjects,\n",
    "         pos_R_2D=pos_R_2D, vel_R_2D=vel_R_2D, peak_acc_2D=peak_acc_2D, acc_time_2D=acc_time_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f43292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4ccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cebra] *",
   "language": "python",
   "name": "conda-env-cebra-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
